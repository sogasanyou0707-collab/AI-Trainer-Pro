import streamlit as st
import os
import json
import requests
import gspread
from google.oauth2.service_account import Credentials
import google.generativeai as genai
from datetime import datetime

# --- 1. è¨­å®šãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç† ---
CONFIG_FILE = "app_settings.json"
SHEET_NAME = "Profiles"

def load_cache():
    """è¨­å®šã‚’èª­ã¿è¾¼ã¿ã€ä¸è¶³é …ç›®ãŒã‚ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è£œå®Œ"""
    defaults = {
        "user_name": "æœªè¨­å®š",
        "user_role": "æœªè¨­å®š",
        "selected_model": "gemini-3-pro",
        "line_token": "",
        "line_user_id": ""
    }
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                defaults.update(data)
        except:
            pass
    return defaults

def save_cache(settings):
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(settings, f, indent=4, ensure_ascii=False)

# --- 2. å¤–éƒ¨é€£æºãƒ­ã‚¸ãƒƒã‚¯ ---
def get_latest_models():
    """1.5ç³»ã‚’é™¤å¤–ã—ãŸæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«å–å¾—"""
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        models = [m.name.replace('models/', '') for m in genai.list_models() 
                if 'generateContent' in m.supported_generation_methods and "1.5" not in m.name]
        return models if models else ["gemini-3-pro"]
    except:
        return ["gemini-3-pro"]

def sync_all_from_sheets():
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®Profilesã‚·ãƒ¼ãƒˆã‹ã‚‰å…¨æƒ…å ±ã‚’åŒæœŸ"""
    try:
        creds_info = st.secrets["connections"]["gsheets"]
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        client = gspread.authorize(creds)
        sh = client.open_by_url(creds_info["spreadsheet"])
        sheet = sh.worksheet(SHEET_NAME)
        
        # å„ã‚»ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾— (A2:åå‰, B2:å½¹å‰², E2:ãƒˆãƒ¼ã‚¯ãƒ³, F2:ID)
        return {
            "user_name": sheet.acell('A2').value,
            "user_role": sheet.acell('B2').value,
            "line_token": sheet.acell('E2').value,
            "line_user_id": sheet.acell('F2').value
        }
    except Exception as e:
        st.error(f"åŒæœŸå¤±æ•—: {e}")
        return None

def ai_get_suggestions(content, model_name, role):
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel(model_name)
        prompt = f"ã‚ãªãŸã¯{role}ã®å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ¥­å‹™å ±å‘Šã«åŸºã¥ãã€æ˜æ—¥ä»¥é™ã®ã‚¿ã‚¹ã‚¯ã‚’3ã¤å…·ä½“çš„ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n\nå†…å®¹:\n{content}"
        return model.generate_content(prompt).text
    except Exception as e:
        return f"ææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"

# --- 3. UI æ§‹ç¯‰ ---
st.set_page_config(page_title="AI Trainer Pro", layout="centered")

if 'cache' not in st.session_state:
    st.session_state.cache = load_cache()
cache = st.session_state.cache

st.title("AI Trainer æ¥­å‹™å ±å‘Š")

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
st.write(f"ğŸ‘¤ **{cache.get('user_name')}** ({cache.get('user_role')})")
selected_date = st.date_input("å ±å‘Šæ—¥ã‚’é¸æŠ", datetime.now())

st.write("---")

report_text = st.text_area("æœ¬æ—¥ã®å ±å‘Šå†…å®¹", placeholder="ã“ã¡ã‚‰ã«æ¥­å‹™å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=250)

if st.button("ğŸš€ LINEã§å ±å‘Šã‚’é€ä¿¡", use_container_width=True):
    if cache.get("line_token") and cache.get("line_user_id"):
        msg = f"ã€{selected_date} å ±å‘Šã€‘\næ‹…å½“: {cache['user_name']}\n---\n{report_text}"
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {cache['line_token']}"}
        data = {"to": cache["line_user_id"], "messages": [{"type": "text", "text": msg}]}
        
        with st.spinner("é€ä¿¡ä¸­..."):
            res = requests.post("https://api.line.me/v2/bot/message/push", headers=headers, json=data)
            if res.status_code == 200:
                st.success("LINEã«é€ä¿¡ã—ã¾ã—ãŸï¼")
            else:
                st.error("é€ä¿¡å¤±æ•—ã€‚")
    else:
        st.warning("è¨­å®šç”»é¢ã‹ã‚‰æƒ…å ±ã‚’åŒæœŸã—ã¦ãã ã•ã„ã€‚")

if st.button("ğŸ’¡ AIã«ã‚¿ã‚¹ã‚¯ã‚’ç›¸è«‡ã™ã‚‹", use_container_width=True):
    if report_text:
        with st.spinner("æ€è€ƒä¸­..."):
            suggestions = ai_get_suggestions(report_text, cache['selected_model'], cache['user_role'])
            st.markdown("### AIã‹ã‚‰ã®ææ¡ˆ")
            st.info(suggestions)
    else:
        st.warning("å…ˆã«å ±å‘Šå†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    with st.expander("è©³ç´°è¨­å®šã‚’é–‹ã", expanded=False):
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        models = get_latest_models()
        cur_model = cache.get("selected_model", "gemini-3-pro")
        idx = models.index(cur_model) if cur_model in models else 0
        cache["selected_model"] = st.selectbox("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", models, index=idx)
        
        st.write("---")
        
        # æƒ…å ±åŒæœŸãƒœã‚¿ãƒ³
        if st.button("LINEæƒ…å ±ã®åŒæœŸ", use_container_width=True):
            with st.spinner("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰å–å¾—ä¸­..."):
                new_data = sync_all_from_sheets()
                if new_data:
                    cache.update(new_data)
                    save_cache(cache)
                    st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®å…¨æƒ…å ±ã‚’åŒæœŸã—ã¾ã—ãŸ")
                    st.rerun()
        
        if st.button("è¨­å®šã‚’ä¿å­˜", use_container_width=True):
            save_cache(cache)
            st.toast("ç¾åœ¨ã®è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")

st.write("---")
st.caption(f"Model: {cache['selected_model']}")
